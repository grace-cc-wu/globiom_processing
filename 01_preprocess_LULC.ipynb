{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zonal statistics using polygons as zones and raster input for calculating statistics\n",
    "---\n",
    "Purpose: preprocess raster datasets for aggregation by SimU \n",
    "\n",
    "This code takes the following data inputs: \n",
    "\n",
    "1. national level SimUs as vector file\n",
    "2. categorical* raster(s) for the years of interest\n",
    "\n",
    "/* note: it will also accept ordinal rasters too, but you will need to then specify the stats to report\n",
    "\n",
    "And produces a csv in the following format:\n",
    "\n",
    "row 1: Name_1  |  FID_SimU_a  |  SimUID  |  HRU  |  Area_1000ha |  Class 1  | Class 2  |  Class n...  |  LULC_areaSum\n",
    "\n",
    "Area of each class and area in LULC_areaSum are in units of 1000 ha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import fiona as fi\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from osgeo import ogr\n",
    "import json\n",
    "import geojson\n",
    "import os\n",
    "from rasterstats import zonal_stats\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Function to calculate zonal stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcZS(zones, rasterPath, statsList, categorical, zones_dropCols, convUnit):\n",
    "    ## rasterstats manual: https://pythonhosted.org/rasterstats/manual.html#zonal-statistics\n",
    "\n",
    "    ## calc zonal stats\n",
    "    stats = zonal_stats(zones, rasterPath, categorical = categorical, stats=statsList, nodata = 0)\n",
    "\n",
    "    ## convert stats output to pd df\n",
    "    stats_df = pd.DataFrame(stats)\n",
    "    \n",
    "    ## change the index to be the same as zones to enable concatenation\n",
    "    stats_df = stats_df.set_index(zones.index)\n",
    "    \n",
    "    ## convert pixel count to unit of interest\n",
    "    stats_df = stats_df*convUnit\n",
    "    ## Create new column that is the sum of all the LULC area categories\n",
    "    stats_df[\"LULC_areaSum\"] = stats_df.sum(axis = 1, skipna = True)\n",
    "    \n",
    "    ## concat the zones columns \n",
    "    stats_df_concat = pd.concat([pd.DataFrame(zones), stats_df], axis = 1, ignore_index = False)\n",
    "    \n",
    "    ## remove any excess columns from the zones df\n",
    "    stats_df_concat.drop(columns = zones_dropCols, inplace = True)\n",
    "\n",
    "    return stats_df_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Parameters \n",
    "set parameters, import datasets, set output file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GENERAL PARAMETERS\n",
    "dataType = \"LULC_l48\" ## Used to name file\n",
    "year = 2016 ## used to name file\n",
    "## columns in include in the final reclassified csv\n",
    "columnsInFinal = [\"UniqueID\", \"COUNTRY\", \"FID_countr\", \"HRU\", \"Grd30\", \"State\", \"FID_SimU_a\", \"SimUID\", \"Area_km2\" ,\"Area_1000ha\", \"LULC_areaSum\", \\\n",
    "                  \"Forest\" , \"CrpLnd\", \"Grass\", \"OthNatLnd\", \"WetLnd\", \"NotRel\"]\n",
    "projectVector = \"yes\" ## yes or not to project the zones/vector file to match the raster projection\n",
    "testRun = \"no\" ## yes or no to run for just a state\n",
    "testRun_state = \"\" ## if yes, this will be the state it will run\n",
    "units = \"1000ha\" ## used to name file\n",
    "viewMaxRows = 20\n",
    "\n",
    "#### ZONAL STATS FUNCTION ARGUMENTS\n",
    "## list: zones/vector column names to drop, if any\n",
    "dropColsLs = [\"geometry\", 'oilp_yield', 'oilp_yie_1', 'oilp_yie_2']\n",
    "## scalar: area of each grid cell to multiply the categorical count to get to units of 1000 ha\n",
    "convUnit_a = 0.00009 \n",
    "## for the above, convUnit_a = 0.00009 for landsat (30 m data) since equal to 900 m2 or 30m x 30m in units of 1000 ha (0.09 ha = 900 m2; divide by 10,000)\n",
    "## boolean: whether or not the raster is categorical\n",
    "categoricalRaster = True\n",
    "## list: stats to calculate (none if categorical raster)\n",
    "statList = []\n",
    "\n",
    "#### INPUT FILE PATHS \n",
    "## Polygon (SimU) datast\n",
    "SimU_fp = \"C:\\\\Users\\\\Grace\\\\Documents\\\\FABLE\\\\GLOBIOM\\\\SimU\\\\gis\\\\SimU_all_select840_USstateSplit_proj.shp\"\n",
    "\n",
    "## Raster dataset\n",
    "raster_fp= \"C:\\\\Users\\\\Grace\\\\Documents\\\\FABLE\\\\GLOBIOM\\\\US_data\\\\LULC\\\\NLCD\\\\NLCD_2016_Land_Cover_L48_20190424\\\\NLCD_2016_Land_Cover_L48_20190424.img\"\n",
    "\n",
    "## legend\n",
    "legend_fp = \"C:\\\\Users\\\\Grace\\\\Documents\\\\FABLE\\\\GLOBIOM\\\\US_data\\\\LULC\\\\NLCD\\\\legend.csv\"\n",
    "leg_col_1 = \"Code\"\n",
    "leg_col_2 = \"Name\"\n",
    "\n",
    "## recclassification legend\n",
    "reclassLegend_fp = \"C:\\\\Users\\\\Grace\\\\Documents\\\\FABLE\\\\GLOBIOM\\\\US_data\\\\LULC\\\\NLCD\\\\NCLD_GLOBIOM_mapping.csv\"\n",
    "reclass_col_1 = \"NLCD_categoryName\"\n",
    "reclass_col_2 = \"GLOBIOM_CategoryName\"\n",
    "\n",
    "#### OUTPUT FILE PATHS\n",
    "## csv filename of state land area totals (for checking later, not an output)\n",
    "totalLandArea_fp = \"C:\\\\Users\\\\Grace\\\\Documents\\\\FABLE\\\\GLOBIOM\\\\US_data\\\\LULC\\\\NLCD\\\\processed\\\\\" + dataType + \"_totalLandArea_\" + units + \"_\" + str(year) + testRun_state + \".csv\"\n",
    "\n",
    "## csv filename of original classes\n",
    "results_fp = \"C:\\\\Users\\\\Grace\\\\Documents\\\\FABLE\\\\GLOBIOM\\\\US_data\\\\LULC\\\\NLCD\\\\processed\\\\\" + dataType + \"_NCLD_SimU_originalClasses_\" + units + \"_\" + str(year) + testRun_state + \".csv\"\n",
    "\n",
    "## csv filename of reclassifed classes\n",
    "results_mapped_fp = \"C:\\\\Users\\\\Grace\\\\Documents\\\\FABLE\\\\GLOBIOM\\\\US_data\\\\LULC\\\\NLCD\\\\processed\\\\\" + dataType + \"_NCLD_SimU_GLOBIOMclasses_\" + units + \"_\" + str(year) + testRun_state + \".csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Preprocess inputs as necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If specified, project the vector/zones file to the same projection as the raster file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "if projectVector == \"yes\":\n",
    "    SimU = gpd.read_file(SimU_fp)\n",
    "    raster = rasterio.open(raster_fp)\n",
    "\n",
    "    SimU_proj = SimU.to_crs(crs=raster.crs.data)\n",
    "    \n",
    "else:\n",
    "    SimU_proj = SimU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename and calculate additional columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add the units to the area column\n",
    "SimU_proj.rename(columns={\"Area\": \"Area_km2\"}, inplace = True)\n",
    "\n",
    "## convert units into 1000ha\n",
    "SimU_proj[\"Area_1000ha\"] = SimU_proj[\"Area_km2\"]*0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run: only use zones from a specified area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testRun == \"yes\":\n",
    "    print(\"Running \" + testRun_state)\n",
    "    SimU_proj = SimU_proj.loc[(SimU_proj['NAME_1'].astype(str) == testRun_state)]\n",
    "    SimU_proj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Run zonal stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "## Run function\n",
    "zs_out = calcZS(zones = SimU_proj, rasterPath = raster_fp, statsList = statList, categorical = categoricalRaster, zones_dropCols = dropColsLs, convUnit = convUnit_a)\n",
    "\n",
    "## report time\n",
    "elapsed_time = (time.time() - start_time)/(60)\n",
    "print(\"^ Total time for completion: \" + str(elapsed_time) + \" minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', viewMaxRows, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(zs_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate total area within states for each state\n",
    "Save to csv to compare with official state land area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## total area in state in 1000ha or 0.1*km2\n",
    "totLndArea = zs_out.groupby(\"NAME_1\").LULC_areaSum.sum()\n",
    "totLndArea.to_csv(totalLandArea_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Replace numerical column names with the official class names and save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = pd.read_csv(legend_fp)\n",
    "\n",
    "## convert the first two columns into a dictionary\n",
    "legend_dict = dict(zip(legend[leg_col_1], legend[leg_col_2]))\n",
    "#NLCDlegend_dict\n",
    "\n",
    "## replace columns using dictionary\n",
    "zs_out_names = zs_out.rename(columns=legend_dict)\n",
    "zs_out_names\n",
    "\n",
    "## rename columns as necessary\n",
    "zs_out_names.rename(columns = {\"NAME_1\": \"State\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export csv with original classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_out_names.to_csv(results_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Reclassify for model requirements and save as another csv\n",
    "\n",
    "This section can be run without running any of the above analysis, just fill out the parameters chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read output from source\n",
    "zs_out_names = pd.read_csv(results_fp)\n",
    "zs_out_names.rename(columns = {\"Unnamed: 0\": \"UniqueID\"}, inplace = True)\n",
    "\n",
    "## read csv with mapping from NLCD to GLOBIOM\n",
    "reclassLegend = pd.read_csv(reclassLegend_fp)\n",
    "\n",
    "## convert the first two columns into a dictionary\n",
    "reclassLegend_dict = dict(zip(reclassLegend[reclass_col_1], reclassLegend[reclass_col_2]))\n",
    "#NLCDlegend_dict\n",
    "\n",
    "## replace columns using dictionary\n",
    "zs_out_names_GLO = zs_out_names.rename(columns=reclassLegend_dict)\n",
    "\n",
    "## Sum the columns with the same names\n",
    "zs_out_names_GLO_summed = zs_out_names_GLO.groupby(zs_out_names_GLO.columns, axis=1).sum()\n",
    "zs_out_names_GLO_summed\n",
    "\n",
    "## reorder columns\n",
    "zs_out_names_GLO_summed = zs_out_names_GLO_summed[columnsInFinal]\n",
    "\n",
    "## save to csv\n",
    "zs_out_names_GLO_summed.to_csv(results_mapped_fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
